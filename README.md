
# ğŸ“„ Job Search AI Pipeline

**AI-powered automation pipeline that downloads newspapers, extracts job listings using OCR and layout detection, translates them, and matches them to your resume using GPT-based semantic filtering. Notifies you via Telegram when relevant jobs are found.**

---

## ğŸš€ Key Features

âœ… Automated newspaper PDF downloads (supports regional & national job newspapers)

âœ… Layout-aware OCR extraction (using PyMuPDF, pdf2image, Detectron2 / LayoutParser, Donut, or Tesseract)

âœ… Translation of non-English job listings (Hindi, Marathi, etc.) to English

âœ… NLP-powered job parsing & keyword extraction

âœ… Resume-job semantic matching using OpenAI GPT (zero-shot/few-shot inference)

âœ… Automatic Telegram alerts for relevant job matches

âœ… Daily pipeline automation (cron/Task Scheduler)

---

## ğŸ”§ Tech Stack

| Domain                      | Tools / Libraries                              |
|-----------------------------|------------------------------------------------|
| ğŸ“¥ PDF Download             | requests, curl                                 |
| ğŸ“„ OCR / Image Processing   | PyMuPDF, pdf2image, pytesseract, Donut         |
| ğŸ§± Layout Detection         | Detectron2 (PubLayNet), LayoutParser           |
| ğŸŒ Translation              | googletrans, IndicTrans (planned)              |
| ğŸ§  AI Matching              | OpenAI GPT-4 API, Zero-shot prompting          |
| ğŸ¤– Notifications            | Telegram Bot API                               |
| ğŸ” Automation               | cron (Linux), Task Scheduler (Windows)         |

---

## ğŸ” Pipeline Workflow

```
Download PDFs
     â†“
Convert PDF to Images
     â†“
Detect Layout Blocks
     â†“
Run OCR or Donut to extract text
     â†“
Translate to English (if required)
     â†“
Parse job listings from text
     â†“
Check match with resume using GPT
     â†“                 â†“
Match Found       No Match
     â†“                 â†“
Send Alert       Delete PDF
```

---

## ğŸ“‚ Folder Structure

```
job-search-ai-pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_pdfs/               # Directly downloaded PDFs (raw)
â”‚   â”œâ”€â”€ processed_pdfs/         # PDFs after layout detection / cleaning
â”‚   â”œâ”€â”€ processed_images/       # Images extracted from PDFs (for OCR/layout detection)
â”‚   â”œâ”€â”€ pdf2img/                # Temp folder for intermediate PDF â†’ image conversions
â”‚   â”œâ”€â”€ extracted_text/         # OCR-extracted raw text from images
â”‚   â””â”€â”€ jobs_json/              # Parsed, structured job data in JSON format
â”‚
â”œâ”€â”€ resumes/
â”‚   â”œâ”€â”€ resume_ee.txt           # Electrical resume
â”‚   â””â”€â”€ resume_aiml.txt         # AI/ML resume
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ download_pdfs.py        # Script to download daily newspaper PDFs
â”‚   â”œâ”€â”€ pdf2img.py              # Convert PDFs to images (using pdf2image, etc.)
â”‚   â”œâ”€â”€ layout_detect_blocks.py # Detect text/image blocks in pages (Detectron2, LayoutParser, etc.)
â”‚   â”œâ”€â”€ layout_donut_pipeline.py# Donut/Transformer-based OCR + layout-aware extraction
â”‚   â”œâ”€â”€ parse_jobs.py           # Rule-based or ML/NLP-based job extraction
â”‚   â”œâ”€â”€ match_resume.py         # Resume-job matching with OpenAI GPT or local LLM
â”‚   â””â”€â”€ feedback_loop.py        # (Future) Self-learning from feedback
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ detectron2_publaynet/   # Pretrained layout detection models (optional)
â”‚
â”œâ”€â”€ main.py                     # Pipeline orchestrator (runs all steps end-to-end)
â”œâ”€â”€ config.yaml                  # Config: API keys, paths, hyperparameters, newspaper URLs
â”œâ”€â”€ README.md                    # Project overview, setup, usage instructions
â””â”€â”€ requirements.txt             # List of dependencies
```


---

## âš™ï¸ Setup Instructions

1. Clone the repository
   ```bash
   git clone https://github.com/<your-username>/job-search-ai-pipeline.git
   cd job-search-ai-pipeline
   ```
   ### ğŸ”— Pretrained Layout Detection Model (PubLayNet)

Download the pretrained Detectron2 PubLayNet model (~330 MB):

```bash
mkdir -p models/detectron2_publaynet
wget -O models/detectron2_publaynet/model_final.pth "https://www.dropbox.com/s/dgy9c10wykk4lq4/model_final.pth?dl=1"
wget -O models/detectron2_publaynet/config.yml "https://raw.githubusercontent.com/Layout-Parser/layout-parser/main/layoutparser/data/PubLayNet/faster_rcnn_R_50_FPN_3x.yaml"
```
   
2. Install dependencies
   ```bash
   pip install -r requirements.txt
   ```
3. Add your configuration in `config.yaml` (OpenAI key, Telegram bot token, etc.)

4. Run the pipeline manually:
   ```bash
   python main.py
   ```

Or schedule it daily via `cron` or Windows Task Scheduler.

---

## ğŸ›¡ï¸ License

Licensed under the **MIT License** â€” free for personal and educational use.

---

## ğŸ“¬ Future Improvements
- Add self-learning feedback loop
- Support multiple resume profiles (EE + AI/ML)
- Deploy as a microservice or Streamlit app
- Add support for more newspapers
